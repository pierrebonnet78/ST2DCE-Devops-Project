pipeline {
    agent {
        kubernetes {
            defaultContainer 'kaniko'
            yaml """
apiVersion: v1
kind: Pod
metadata:
  name: kaniko
spec:
  containers:
    - name: git
      image: alpine/git
      command:
        - /bin/cat
      tty: true
      volumeMounts:
        - name: shared-workspace
          mountPath: /workspace
    - name: kaniko
      image: gcr.io/kaniko-project/executor:debug
      command:
        - /busybox/cat
      tty: true
      volumeMounts:
        - name: shared-workspace
          mountPath: /workspace
    - name: deployer
      image: dtzar/helm-kubectl:latest
      command:
        - /bin/cat
      tty: true
      volumeMounts:
        - name: shared-workspace
          mountPath: /workspace
  volumes:
    - name: shared-workspace
      emptyDir: {}
"""
        }
    }

    stages {
        stage('Checkout') {
            steps {
                container('git') {
                    sh '''
                    rm -rf /workspace/* || true
                    git clone https://github.com/pierrebonnet78/ST2DCE-Devops-Project.git /workspace/project
                    '''
                }
            }
        }
        /*

        stage('Get Minikube Registry IP Address') {
            steps {
                container('deployer') {
                    script {
                        withCredentials([file(credentialsId: 'conf', variable: 'KUBECONFIG')]) {
                            sh '''
                            mkdir -p /root/.kube
                            cp $KUBECONFIG /root/.kube/config
                            REGISTRY_IP=$(kubectl get svc registry -n kube-system -o jsonpath='{.spec.clusterIP}')
                            echo "REGISTRY_IP=$REGISTRY_IP" > /workspace/registry.env
                            '''
                        }
                    }
                }
            }
        }

        stage('Build Docker Image') {
            steps {
                container('kaniko') {
                    sh '''
                    source /workspace/registry.env
                    echo "Building image and pushing to $REGISTRY_IP:80"
                    
                    /kaniko/executor \
                        --dockerfile=/workspace/project/Dockerfile \
                        --context=/workspace/project \
                        --destination=$REGISTRY_IP:80/go-app:${BUILD_NUMBER} \
                        --insecure \
                    '''
                }
            }
        }

        stage('Deploy to Development') {
            steps {
                container('deployer') {
                    withCredentials([file(credentialsId: 'conf', variable: 'KUBECONFIG')]) {
                        sh '''
                        source /workspace/registry.env
                        
                        # Create development namespace if it doesn't exist
                        kubectl create namespace development --dry-run=client -o yaml | kubectl apply -f -
                        
                        # Copy kubeconfig
                        mkdir -p /root/.kube
                        cp $KUBECONFIG /root/.kube/config
                        
                        # Replace image and namespace in deployment file
                        sed -i "s|image: .*|image: $REGISTRY_IP:80/go-app:${BUILD_NUMBER}|g" /workspace/project/deployment/k8s_deployment_dev.yaml
                        
                        # Apply the deployment to development namespace
                        kubectl apply -f /workspace/project/deployment/k8s_deployment_dev.yaml -n development
                        
                        # Wait for deployment with timeout
                        timeout 300s kubectl rollout status deployment/go-app-deployment -n development || exit 1
                        
                        # Show deployment status
                        echo "Development deployment status:"
                        kubectl get deployments,pods,services -n development
                        '''
                    }
                }
            }
        }

        stage('Test Application Endpoint') {
            steps {
                container('deployer') {
                    withCredentials([file(credentialsId: 'conf', variable: 'KUBECONFIG')]) {
                        sh '''
                        # Wait for service to get an IP and endpoints to be ready
                        echo "Waiting for service to be ready..."
                
                # Wait for endpoints to be ready (max 60 seconds)
                for i in $(seq 1 30); do
                    if kubectl get endpoints go-app-service -n development -o jsonpath='{.subsets[0].addresses[0].ip}' > /dev/null 2>&1; then
                        echo "Service endpoints are ready!"
                        break
                        fi
                        echo "Waiting for service endpoints... (Attempt $i/30)"
                        sleep 2
                        if [ $i -eq 30 ]; then
                            echo "Timeout waiting for service endpoints"
                            exit 1
                        fi
                        done
                        
                        # Get service URL
                        SERVICE_IP=$(kubectl get svc go-app-service -n development -o jsonpath='{.spec.clusterIP}')
                        SERVICE_PORT=$(kubectl get svc go-app-service -n development -o jsonpath='{.spec.ports[0].port}')
                        SERVICE_URL="http://${SERVICE_IP}:${SERVICE_PORT}"
                        
                        echo "Testing service at ${SERVICE_URL}"
                        
                        # Test the endpoint
                        response=$(curl -s -o /dev/null -w "%{http_code}" ${SERVICE_URL}/whoami)
                        
                        if [ "$response" = "200" ]; then
                            echo "Test passed! Service returned 200"
                        else
                            echo "Test failed! Service returned $response"
                            exit 1
                        fi
                        '''
                    }
                }
            }
        }

        stage('Deploy to Production') {
            steps {
                container('deployer') {
                    withCredentials([file(credentialsId: 'conf', variable: 'KUBECONFIG')]) {
                        sh '''
                        source /workspace/registry.env
                        
                        # Create production namespace if it doesn't exist
                        kubectl create namespace production --dry-run=client -o yaml | kubectl apply -f -
                        
                        # Replace image and namespace in deployment file
                        sed -i "s|image: .*|image: $REGISTRY_IP:80/go-app:${BUILD_NUMBER}|g" /workspace/project/deployment/k8s_deployment_prod.yaml
                        
                        # Apply the deployment to production namespace
                        kubectl apply -f /workspace/project/deployment/k8s_deployment_prod.yaml -n production
                        
                        # Wait for deployment with timeout
                        timeout 300s kubectl rollout status deployment/go-app-deployment -n production || exit 1
                        
                        # Show deployment status
                        echo "Production deployment status:"
                        kubectl get deployments,pods,services -n production
                        '''
                    }
                }
            }
        }
        */

        stage('Install Monitoring Stack') {
    steps {
        container('deployer') {
            withCredentials([file(credentialsId: 'conf', variable: 'KUBECONFIG')]) {
                sh '''
                # Create monitoring namespace
                kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -

                # Add Helm repositories
                helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
                helm repo add grafana https://grafana.github.io/helm-charts
                helm repo update

                helm upgrade --install prometheus-operator prometheus-community/kube-prometheus-stack \
                    --set defaultRules.create=false \
                    --namespace monitoring \
                    --set prometheusOperator.admissionWebhooks.enabled=true \
                    --set prometheusOperator.createCustomResource=false \
                    --set grafana.enabled=true \
                    --set grafana.adminPassword=admin \
                    --set alertmanager.enabled=true \
                    --set prometheus.enabled=true \
                    --wait

                # Wait for Prometheus Operator to be ready
                echo "Waiting for Prometheus Operator pods to be ready..."
                kubectl wait --for=condition=available deployment.apps/prometheus-operator-kube-p-operator -n monitoring --timeout=300s


                # Apply PrometheusRules from external file
                kubectl apply -f /workspace/project/deployment/prometheus-alerts.yaml

                # Apply AlertManager config
                kubectl apply -f /workspace/project/deployment/alertmanager-config.yaml

                # Verify Prometheus rules are loaded
                echo "Waiting for Prometheus to be ready..."
                sleep 10

                PROMETHEUS_POD=$(kubectl get pods -n monitoring -l "app.kubernetes.io/name=prometheus,prometheus=prometheus-operator-kube-p-prometheus" -o jsonpath="{.items[0].metadata.name}")
                if [ -z "$PROMETHEUS_POD" ]; then
                    echo "No Prometheus pod found. Checking all pods in monitoring namespace:"
                    kubectl get pods -n monitoring --show-labels
                    exit 1
                fi


                echo "Checking configured rules..."
                kubectl exec -n monitoring $PROMETHEUS_POD -c prometheus -- wget -qO- http://localhost:9090/api/v1/rules || true
                '''
            }
        }
    }
}


        stage('Configure Grafana Dashboard') {
            steps {
                container('deployer') {
                    withCredentials([file(credentialsId: 'conf', variable: 'KUBECONFIG')]) {
                        sh '''
                        # Wait for Grafana to be ready
                        kubectl rollout status deployment/prometheus-operator-grafana -n monitoring
                        
                        # Get Grafana pod name
                        GRAFANA_POD=$(kubectl get pods -n monitoring -l app.kubernetes.io/name=grafana -o jsonpath='{.items[0].metadata.name}')
                        
                        # Import Kubernetes dashboard
                        kubectl exec -n monitoring $GRAFANA_POD -- curl -X POST \
                            -H "Content-Type: application/json" \
                            -d '{"dashboard": {"id": null,"title": "Kubernetes Cluster","timezone": "browser","schemaVersion": 16,"version": 0},"folderId": 0,"overwrite": true}' \
                            http://admin:admin@localhost:3000/api/dashboards/db
                        
                        echo "Grafana dashboard has been configured"
                        '''
                    }
                }
            }
        }
    }

    post {
        success {
            echo """
            Pipeline completed successfully!
            
            To access Grafana:
            1. Run: kubectl port-forward -n monitoring svc/prometheus-operator-grafana 3000:80
            2. Visit: http://localhost:3000
            3. Login with:
               Username: admin
               Password: admin

            To access AlertManager:
            1. Run: kubectl port-forward -n monitoring svc/prometheus-operator-kube-p-alertmanager 9093:9093
            2. Visit: http://localhost:9093

            To access Prometheus:
            1. Run: kubectl port-forward -n monitoring svc/prometheus-operated 9090:9090
            2. Visit: http://localhost:9090
            """
        }
    }
}